<!doctype html><html lang=en><head><meta charset=utf-8><meta name=generator content="Hugo 0.101.0"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content><meta property="og:url" content="https://qige96.github.io/myblog/posts/explaining-probability-calibration/"><link rel=canonical href=https://qige96.github.io/myblog/posts/explaining-probability-calibration/><link rel=alternate type=application/atom+xml href=https://qige96.github.io/myblogindex.xml title="Blog of Ricky"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/qige96.github.io\/myblog"},"articleSection":"posts","name":"Explaining Probability Calibration","headline":"Explaining Probability Calibration","description":"This is a reading note explaining what probability calibration is, why we should use it, and how to achieve it. I will firstly introduce the origin of this notion, and then explain how to achieve probability calibration and why this can work. Lastly, I reveal the benefits of probability calibration.\nPhilosophical Origin What is probability calibration? In a word, calibration means the forecast probabilities match the relative frequencies: \\(fr(X|pr(X)=\\beta)=\\beta\\), where \\(fr(X)\\) represents the relative frequency of \\(X\\) and \\(pr(X)\\) represents the predicted probability of \\(X\\).","inLanguage":"en-US","author":"","creator":"","publisher":"","accountablePerson":"","copyrightHolder":"","copyrightYear":"2022","datePublished":"2022-07-30 00:27:00 \u002b0100 \u002b0100","dateModified":"2022-07-30 00:27:00 \u002b0100 \u002b0100","url":"https:\/\/qige96.github.io\/myblog\/posts\/explaining-probability-calibration\/","keywords":[]}</script><title>Explaining Probability Calibration</title><meta property="og:title" content="Explaining Probability Calibration"><meta property="og:type" content="article"><meta property="og:description" content="This is a reading note explaining what probability calibration is, why we should use it, and how to achieve it. I will firstly introduce the origin of this notion, and then explain how to achieve probability calibration and why this can work. Lastly, I reveal the benefits of probability calibration.
Philosophical Origin What is probability calibration? In a word, calibration means the forecast probabilities match the relative frequencies: \(fr(X|pr(X)=\beta)=\beta\), where \(fr(X)\) represents the relative frequency of \(X\) and \(pr(X)\) represents the predicted probability of \(X\)."><meta name=description content="This is a reading note explaining what probability calibration is, why we should use it, and how to achieve it. I will firstly introduce the origin of this notion, and then explain how to achieve probability calibration and why this can work. Lastly, I reveal the benefits of probability calibration.
Philosophical Origin What is probability calibration? In a word, calibration means the forecast probabilities match the relative frequencies: \(fr(X|pr(X)=\beta)=\beta\), where \(fr(X)\) represents the relative frequency of \(X\) and \(pr(X)\) represents the predicted probability of \(X\)."><meta property="og:locale" content="en-us"><meta property="og:image" content><style>body{font-family:bree serif,sans-serif;-webkit-font-smoothing:antialiased;margin:0 20px}article{max-width:800px;margin-left:auto;margin-right:auto}a{color:#000;text-decoration:none}a:hover{font-weight:600;text-decoration:underline}.post-ads{margin:50px 0}.markdown-body{font-size:18px;max-width:100%}.markdown-body a{text-decoration:underline;text-decoration-color:#000}.markdown-body blockquote{margin:0;padding:0 1em;color:#57606a;border-left:.25em solid #d0d7de}.markdown-body pre{padding:16px;overflow:auto;border-radius:10px}.markdown-body code{padding:.2em .4em;font-size:85%;background-color:#f6f8fa;border-radius:6px}.markdown-body pre>code{padding:0;font-size:100%;background-color:inherit;border:0}.Chinese .markdown-body{line-height:200%}.site-date-catalog{font-size:2rem}.header-title{font-size:2rem;font-weight:700;margin-top:32px;font-family:bungee shade,sans-serif}.header-title a{text-decoration:none}.header-subtitle{color:#666}.header-items{margin:10px 0}.header-item{margin:0 5px}.header-line{width:100%;border-width:2px;border-color:#482936;border-style:solid none none none}.lang-switch{font-weight:600}#posts-list{min-height:600px}.posts-line{font-size:1.2rem;margin:12px 0}.posts-categories{font-size:.8rem;margin:auto;text-align:center}.posts-category{padding:3px 0;border:#000 2px solid;border-radius:5px}.site-footer{margin-top:50px}.site-footer-item{margin-right:12px}.post-content img{max-width:100%;display:block;margin-right:auto;margin-top:12px}.post-header{margin-bottom:50px}.post-title{font-size:2rem;font-weight:600}.post-tags{display:inline;font-weight:600;padding:2px 5px;margin-right:6px;border:#000 2px solid;border-radius:5px}.post-date{font-weight:800;font-style:italic}.post-author{float:right;font-weight:600}.page-content{min-height:60%}.post-content{margin-bottom:50px}.post-content p{hyphens:auto;line-height:1.8;text-justify:ideographic;margin-bottom:1em}.related-content{border-width:3px;border-style:solid;border-color:#000;padding:0 10px;margin-bottom:50px;margin-top:100px}.related-content li{margin:5px 0}.taxonomy-term{font-size:3rem}.gallery-img{text-align:center}.gallery-img span{text-align:center}.gallery-img-desc{font-size:.8em;font-weight:800}#disqus_thread{position:relative}#disqus_thread:after{content:"";display:block;height:55px;width:100%;position:absolute;bottom:0;background:#fff}@media screen and (max-width:600px){.header-title,.header-subtitle,.header-items{text-align:center}.posts-line{font-size:16px}.markdown-body{font-size:16px}.post-title{font-size:2rem}.post-content p{letter-spacing:.05em}}@media screen and (max-width:48em){.posts-category{display:none}}</style><style>.container,.container-fluid{margin-right:auto;margin-left:auto}.container-fluid{padding-right:2rem;padding-left:2rem}.row{box-sizing:border-box;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 1 auto;flex:initial;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-right:-.5rem;margin-left:-.5rem}.row.reverse{-webkit-box-orient:horizontal;-webkit-box-direction:reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse}.col.reverse{-webkit-box-orient:vertical;-webkit-box-direction:reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse}.col-xs,.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9,.col-xs-offset-0,.col-xs-offset-1,.col-xs-offset-10,.col-xs-offset-11,.col-xs-offset-12,.col-xs-offset-2,.col-xs-offset-3,.col-xs-offset-4,.col-xs-offset-5,.col-xs-offset-6,.col-xs-offset-7,.col-xs-offset-8,.col-xs-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-xs{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-xs-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-xs-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-xs-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-xs-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-xs-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-xs-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-xs-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-xs-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-xs-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-xs-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-xs-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-xs-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-xs-offset-0{margin-left:0}.col-xs-offset-1{margin-left:8.33333333%}.col-xs-offset-2{margin-left:16.66666667%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-4{margin-left:33.33333333%}.col-xs-offset-5{margin-left:41.66666667%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-7{margin-left:58.33333333%}.col-xs-offset-8{margin-left:66.66666667%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-10{margin-left:83.33333333%}.col-xs-offset-11{margin-left:91.66666667%}.start-xs{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-xs{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-xs{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-xs{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-xs{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-xs{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-xs{-ms-flex-pack:distribute;justify-content:space-around}.between-xs{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-xs{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-xs{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}@media only screen and (min-width:48em){.container{width:49rem}.col-sm,.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-sm-offset-0,.col-sm-offset-1,.col-sm-offset-10,.col-sm-offset-11,.col-sm-offset-12,.col-sm-offset-2,.col-sm-offset-3,.col-sm-offset-4,.col-sm-offset-5,.col-sm-offset-6,.col-sm-offset-7,.col-sm-offset-8,.col-sm-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-sm{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-sm-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-sm-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-sm-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-sm-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-sm-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-sm-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-sm-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-sm-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-sm-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-sm-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-sm-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-sm-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-sm-offset-0{margin-left:0}.col-sm-offset-1{margin-left:8.33333333%}.col-sm-offset-2{margin-left:16.66666667%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-4{margin-left:33.33333333%}.col-sm-offset-5{margin-left:41.66666667%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-7{margin-left:58.33333333%}.col-sm-offset-8{margin-left:66.66666667%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-10{margin-left:83.33333333%}.col-sm-offset-11{margin-left:91.66666667%}.start-sm{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-sm{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-sm{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-sm{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-sm{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-sm{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-sm{-ms-flex-pack:distribute;justify-content:space-around}.between-sm{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-sm{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-sm{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:64em){.container{width:65rem}.col-md,.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-md-offset-0,.col-md-offset-1,.col-md-offset-10,.col-md-offset-11,.col-md-offset-12,.col-md-offset-2,.col-md-offset-3,.col-md-offset-4,.col-md-offset-5,.col-md-offset-6,.col-md-offset-7,.col-md-offset-8,.col-md-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-md{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-md-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-md-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-md-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-md-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-md-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-md-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-md-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-md-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-md-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-md-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-md-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-md-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-md-offset-0{margin-left:0}.col-md-offset-1{margin-left:8.33333333%}.col-md-offset-2{margin-left:16.66666667%}.col-md-offset-3{margin-left:25%}.col-md-offset-4{margin-left:33.33333333%}.col-md-offset-5{margin-left:41.66666667%}.col-md-offset-6{margin-left:50%}.col-md-offset-7{margin-left:58.33333333%}.col-md-offset-8{margin-left:66.66666667%}.col-md-offset-9{margin-left:75%}.col-md-offset-10{margin-left:83.33333333%}.col-md-offset-11{margin-left:91.66666667%}.start-md{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-md{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-md{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-md{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-md{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-md{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-md{-ms-flex-pack:distribute;justify-content:space-around}.between-md{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-md{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-md{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:75em){.container{width:76rem}.col-lg,.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-lg-offset-0,.col-lg-offset-1,.col-lg-offset-10,.col-lg-offset-11,.col-lg-offset-12,.col-lg-offset-2,.col-lg-offset-3,.col-lg-offset-4,.col-lg-offset-5,.col-lg-offset-6,.col-lg-offset-7,.col-lg-offset-8,.col-lg-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-lg{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-lg-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-lg-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-lg-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-lg-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-lg-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-lg-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-lg-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-lg-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-lg-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-lg-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-lg-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-lg-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-lg-offset-0{margin-left:0}.col-lg-offset-1{margin-left:8.33333333%}.col-lg-offset-2{margin-left:16.66666667%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-4{margin-left:33.33333333%}.col-lg-offset-5{margin-left:41.66666667%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-7{margin-left:58.33333333%}.col-lg-offset-8{margin-left:66.66666667%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-10{margin-left:83.33333333%}.col-lg-offset-11{margin-left:91.66666667%}.start-lg{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-lg{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-lg{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-lg{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-lg{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-lg{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-lg{-ms-flex-pack:distribute;justify-content:space-around}.between-lg{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-lg{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-lg{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}</style><link rel=stylesheet href=https://qige96.github.io/myblog/css/extra.css><link href=https://qige96.github.io/myblog/index.xml rel=alternate type=application/rss+xml title="Blog of Ricky"><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css?family=Bree+Serif|Bungee+Shade" rel=stylesheet><script src=https://qige96.github.io/myblog/js/mathjax-config.js></script>
<script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.6.0/build/styles/default.min.css><script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.6.0/build/highlight.min.js></script>
<script>hljs.highlightAll()</script></head><body><article class=post id=article><div class=row><div class=col-xs-12><div class=site-header><header><div class=header-title><a href=https://qige96.github.io/myblog/>My Sketch Pad</a></div><div class=header-subtitle></div></header><div class="row end-md center-xs header-items"></div><div class="row end-xs"></div><div class=header-line></div></div><header class=post-header><h1 class=post-title>Explaining Probability Calibration</h1><div class="row post-desc"><div class=col-xs-6><time class=post-date datetime="2022-07-30 00:27:00 +0100">30 Jul 2022</time></div><div class=col-xs-6></div></div></header><div class="post-content markdown-body"><p>This is a reading note explaining what probability calibration is,
why we should use it, and how to achieve it. I will firstly introduce
the origin of this notion, and then explain how to achieve probability
calibration and why this can work. Lastly, I reveal the benefits of
probability calibration.</p><h2 id=philosophical-origin>Philosophical Origin</h2><p>What is probability calibration? In a word, calibration means the
forecast probabilities match the relative frequencies: <span class="math inline">\(fr(X|pr(X)=\beta)=\beta\)</span>, where <span class="math inline">\(fr(X)\)</span> represents the relative frequency
of <span class="math inline">\(X\)</span> and <span class="math inline">\(pr(X)\)</span> represents the predicted
probability of <span class="math inline">\(X\)</span>. It originated in
1983 by van Fraassen<a href=#fn1 class=footnote-ref id=fnref1 role=doc-noteref><sup>1</sup></a>, from a philosophical inquiry of an
epistemic virtue for partial beliefs (aka, subjective probabilities,
credence), analogous to the virtue of truth for full beliefs.</p><p>Let’s think about a concrete scenario. Suppose that I would like to
go to a picnic tomorrow. But here in Edinburgh it often rains. If it
won’t rain tomorrow then I can begin to buy some food and make phone
calls to friends. If it will rain tomorrow then I shall not bother
preparing. The key question is whether it will rain tomorrow. I can make
a prediction that “Tomorrow it will rain!” I can verify this prediction
by waiting for tomorrow’s actual weather. By this verification, I can
say that my full belief prediction has an epistemic virtue of truth,
meaning that I can assert it a good prediction if it matches the
reality, or a bad prediction if it failed to match the reality. What if
I make a prediction that “It seems 70% probable to rain tomorrow”? We
cannot verify this prediction through the actual result of tomorrow’s
weather, even it would rain tomorrow indeed. Although we cannot verify
the truth of my partial belief by one prediction, we can evaluate the
<em>quality</em> of my partial beliefs in a long series of
predictions.</p><p>Weather forecasters are evaluated by a widely accepted metric called
Brier Score. Suppose that I care about the weather of Edinburgh, and
predict my subjective probabilities <span class="math inline">\(p_i \in
[0,1]\)</span> for <span class="math inline">\(N\)</span> days, and
denote <span class="math inline">\(y_i \in \{0, 1\}\)</span> as the
actual weather of these <span class="math inline">\(N\)</span> days,
where <span class="math inline">\(0\)</span> standards for not raining,
and <span class="math inline">\(1\)</span> vice versa. Then, the Brier
Score is <span class="math display">\[
BS = \frac{1}{N}\sum_{i=1}^N (p_i - y_i)^2
\]</span></p><p>But this Brier Score doesn’t measure the epistemic virtue we are
looking for. It was shown that the Brier Score is a combination of two
criteria: <strong>informativeness</strong>(refinement) and
<strong>vindication</strong>(calibration). Formally, suppose that among
all the forecast probabilities <span class="math inline">\(p_1, ...,
p_N\)</span> there are <span class="math inline">\(K\)</span> different
numeric values <span class="math inline">\(p_1, ..., p_K (K \le
N)\)</span>. Denote <span class="math inline">\(n_j\)</span> as the
number of days associated with the probability <span class="math inline">\(p_j\)</span>, and <span class="math inline">\(r_j\)</span> as the rate(relative frequency) of
rainy days during these <span class="math inline">\(n_j\)</span> days.
Then, the Brier Score can be decomposed into the calibration term and
the refinement term as: <span class="math display">\[
BS = C + R = [\frac{1}{K}\sum_{j=1}^K n_j(p_j - r_j)^2] +
[\frac{1}{K}\sum_{j=1}^K n_jr_j(1 - r_j)]
\]</span></p><p>The informativeness tends to improve if the forecast probabilities
get closer to <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>. The calibration tends to improve if
the forecast probabilities match the proportion, meaning that if it
rained 70% of the days on which I predicted the probability of raining
was 0.7, and so on for other values. Either of the two terms improves
will finally make the Brier Score improve. As van Fraassen said,
informativeness and vindication are two commonly demanded criteria, and
usually, they are in “desperate tension”. The more informative of the
theory, the less we are sure of the theory. For the following
predictions, “It seems to rain tomorrow”, “It seems 70% probable to rain
tomorrow”, and “It is to rain tomorrow”, we get more and more
information, but we are less and less sure about the prediction, the
greater chance the prediction will be falsified.
Here,<strong>vindication, or calibration, is the epistemic virtue of
partial beliefs we are looking for in analogy to the virtue of truth of
full beliefs, such that the beliefs should <em>match the
world</em>.</strong></p><p>Later Carl Hoefer further explained<a href=#fn2 class=footnote-ref id=fnref2 role=doc-noteref><sup>2</sup></a>
that vindication, or calibration, is merely one of many virtues. If one
can increase calibration without hurting other virtues, then s/he is
rational to do so. However, often virtues can contradict one another.
For example, if I calculate the overall frequency <span class="math inline">\(freq\)</span> of raining during the <span class="math inline">\(N\)</span> days, and make all the forecast
probabilities equal to this frequency <span class="math inline">\(\forall{i} \in \{1,2,..,N \} \quad p_i :=
freq\)</span>, then my forecast probabilities are perfectly calibrated,
but it hurt informativeness, and the overall quality (e.g. the Brier
Score) gets decreased. Which virtues we should choose to pursue involves
trade-offs depending on the specific problems.</p><h2 id=technical-mechanism>Technical Mechanism</h2><p>In Machine Learning, probability calibration is also a family of
techniques to obtain well-calibrated probabilities. Some statistical
classifiers produce scores that are NOT probabilities, such as Support
Vector Machine. Calibration can be used to convert these scores into
probabilities<a href=#fn3 class=footnote-ref id=fnref3 role=doc-noteref><sup>3</sup></a>. Sometimes even probabilistic
classifiers do not produce calibrated distribution, due to over-fitting
or other reasons<a href=#fn4 class=footnote-ref id=fnref4 role=doc-noteref><sup>4</sup></a>. In this case, calibration methods
can also be applied.</p><p>In principle, we can see the original classifiers <span class="math inline">\(f(\boldsymbol{x}|\boldsymbol{w})\)</span> as
feature extractors<a href=#fn5 class=footnote-ref id=fnref5 role=doc-noteref><sup>5</sup></a>. They take raw input data and
produce scores and (uncalibrated) probabilities as features of the input
data. Then a calibration model, essential a simple probabilistic
classifier <span class="math inline">\(p[f(\boldsymbol{x}|\boldsymbol{w})|\boldsymbol{\theta}]\)</span>
like logistic regression, can be applied to learn on these extracted
features, and output calibrated probabilities. We call this method
post-calibration, meaning post-processing the output of the original
model to produce well-calibrated probabilities.</p><p>Why does this post-calibration idea work? Why do those original
models (even probabilistic) fail to produce well-calibrated
probabilities? A recent paper<a href=#fn6 class=footnote-ref id=fnref6 role=doc-noteref><sup>6</sup></a> gives an explanation. If
we assume there exist a “true distribution”, then this true distribution
is well-calibrated by nature. Once our probabilistic model successfully
learns that true distribution, then our learnt distribution will also be
well-calibrated. However, that’s not the case. Our model may get
over-fitting to the training set. The more complicated our model, like
deep neural networks, the more possible it is to get over-fitting.
Another reason could be that the feature space and/or the landscape of
the loss function are too complex that our learning model may be trapped
in local optima, during optimisation. Because of these, our model (even
probabilistic) usually learns an approximate distribution far away from
the true distribution, and thus produces uncalibrated probabilities.
Post-calibration techniques use simple probabilistic models, such as
logistic regression, or one-layer probabilistic neural networks to learn
from a simple feature space, which is the original output of the model,
such as scores of an SVM model, or uncalibrated probabilities of a deep
probabilistic neural network.</p><p>When using post-calibration methods, we should have at least 3
datasets for training <span class="math inline">\((\boldsymbol{X_{train}}, y_{train})\)</span>,
calibration <span class="math inline">\((f(\boldsymbol{X_{cal}}|\boldsymbol{w}),
y_{cal})\)</span>, and testing <span class="math inline">\((\boldsymbol{X_{test}}, y_{test})\)</span>. We
train the original model on the training set, and train a calibrator on
the calibration set, and evaluate the performance, including how
accurate the prediction is and how well-calibrated the probabilities on
the test set.</p><p>How do we check if a forecast distribution is well-calibrated? In the
last section, we decomposed the Brier Score into the calibration term
and refinement term. In theory, the calibration term <span class="math inline">\(C = \frac{1}{K}\sum_{j=1}^K n_j(p_j -
r_j)^2\)</span> can serve as a metric. Yet there are practical
difficulties. The calibration term requires to group events by its exact
probability <span class="math inline">\(p_j\)</span>, and compute the
relative frequency of these <span class="math inline">\(n_j\)</span>
events. This requires the <span class="math inline">\(n_j\)</span> to be
big enough for every unique probability value <span class="math inline">\(p_j\)</span> to produce a frequency value of
statistical significance. But it is rare in practice. Mostly we have
events whose probability value <span class="math inline">\(p_j\)</span>
occurs only once, and the corresponding <span class="math inline">\(n_j\)</span> equals 1, where it is impossible to
calculate a meaningful frequency value. As a compromise, we sometimes
use directly the Brier Score to evaluate probability calibration. Or we
make some relaxation to the grouping criteria, not to group events by
their <em>exact</em> probabilities, but <em>similar</em> probabilities,
so that each group can have enough events to calculate a meaningful
frequency. This is how the widely used ECE(Expected Calibration Error)<a href=#fn7 class=footnote-ref id=fnref7 role=doc-noteref><sup>7</sup></a>works. <span class="math display">\[
ECE = \frac{1}{n}\sum_i^n |pr_i - fr_i|
\]</span> where <span class="math inline">\(pr_i\)</span> represents the
average probability of the <span class="math inline">\(i\)</span>th
group and <span class="math inline">\(fr_i\)</span> represents the
relative frequency of the <span class="math inline">\(i\)</span>th
group. Here is a naive example: <span class="math display">\[
P = [(0.11,0.12,0.13,0.14,0.15), (0.81,0.82,0.83,0.84,0.85)]
\]</span> <span class="math display">\[
Y = [(0,0,0,0,1), (1,1,1,1,0)]
\]</span> <span class="math display">\[
ECE = \frac{1}{2} (|0.13-0.2| + |0.83-0.8|)=0.10
\]</span></p><p>In this example, there are only events whose predicted probability
value occurs only once. We group the events with close probabilities
into 2 clusters, and calculate the average probabilities and relative
frequencies of these 2 clusters, and compare the cumulative distances,
which is <span class="math inline">\(0.10\)</span>, a relatively small
and satisfying results.</p><h2 id=theoretical-benefits>Theoretical Benefits</h2><p>Well-calibrated probabilities are beneficial, especially for critical
applications that rely on accurate probabilities, such as healthcare
diagnosis.</p><p>The most important benefit of distribution calibration should be
<strong>Accurate Loss Estimation</strong><a href=#fn8 class=footnote-ref id=fnref8 role=doc-noteref><sup>8</sup></a>:
for Bayesian decision tasks, the simulated loss computed by the
predicted distribution equals the true loss computed by the true
distribution. That is to say, with well-calibrated predicted
probabilities, the downstream decision makers can accurately estimate
the loss as if they have the true probabilities. In other words, the
calibrated probabilities are indistinguishable in terms of loss
estimation for downstream makers.</p><p>Formally, we consider the binary classification problem with feature
data <span class="math inline">\(X \in \mathbb{R}^m\)</span> and label
data <span class="math inline">\(Y \in \{0,1\}\)</span>. A probabilistic
predictor takes <span class="math inline">\(X\)</span> as input and
produces a probability value <span class="math inline">\(\hat{p}: X
\rightarrow [0,1]\)</span>. Here we denote <span class="math inline">\(\hat{p}(X)\)</span> as the predicted distribution
and <span class="math inline">\(p^*(X)\)</span> as the true
distribution. We assume a downstream application can be formalised as a
decision making problem written in the form of loss minimisation with a
loss function <span class="math inline">\(\mathcal{\ell}\)</span> and
the corresponding action space <span class="math inline">\(\mathcal{A}\)</span>: <span class="math inline">\(\mathcal{\ell}: Y \times \mathcal{A} \rightarrow
\mathbb{R}\)</span>. If the decision making task is Bayes Decision, then
we can define the decision function as <span class="math display">\[
\delta_{\mathcal{\ell}}(\hat{p}(X)) = \mathop{\arg\inf}_{a \in
\mathcal{A}}\mathbb{E}_{\hat{Y} \sim \hat{p}(X)}[\mathcal{\ell}(\hat{Y},
a)]
\]</span></p><p>If our predictor <span class="math inline">\(\hat{p}\)</span>
achieves distribution calibration, meaning <span class="math inline">\(\mathbb{E}[Y|\hat{p}(X)=\beta]=\beta\)</span>,
then we have Accurate Loss Estimation<a href=#fn9 class=footnote-ref id=fnref9 role=doc-noteref><sup>9</sup></a>:</p><p><span class="math display">\[
\mathbb{E}_ {X} \mathbb{E}_{\hat{Y} \sim \hat{p}(X)}
[\mathcal{\ell}(\hat{Y}, \delta_{\mathcal{\ell}}(\hat{p}(X)))] =
\mathbb{E}_X\mathbb{E}_{Y \sim p^*(X)} [\mathcal{\ell}(Y,
\delta_{\mathcal{\ell}}(\hat{p}(X)))]
\]</span></p><p>This important property ensures that the decision maker can know the
expected loss incurred over the distribution of individuals in advance
and prepare for it.</p><p>The concept of distribution calibration can be extended to
multi-class classification, and it it has the property of Accurate Loss
Estimation. We can define label data as <span class="math inline">\(Y
\in \{0, 1, ..., K\}\)</span>, the predicted distribution as <span class="math inline">\(\hat{p}: X \rightarrow \Delta^C\)</span> where
<span class="math inline">\(\Delta^C\)</span> is a C-dimension simplex,
and the criterion of distribution calibration becomes <span class="math inline">\(\forall\beta \in \Delta^C \quad
\mathbb{E}[Y|\hat{p}(X)=\beta]=\beta\)</span>.</p><h2 id=conclusion>Conclusion</h2><p>In this note, I explained the notion of probability calibration in
the aspect of its origin, its mechanism, and its benefits. This notion
originated from a philosophical inquiry of an epistemic virtue for
partial beliefs analogous to the virtue of truth for full beliefs, and
calibration is the epistemic virtue we wanted. Then we briefly
introduced a family of techniques called post-calibration in Machine
Learning, and explained how and why they work. In the final section, I
revealed the most important benefit of probability calibration: Accurate
Loss Estimation. If our predicted distribution is well-calibrated, then
it ensures that we can accurately estimate the loss as if we have the
true distribution in Bayesian decision making tasks.</p><section class="footnotes footnotes-end-of-document" role=doc-endnotes><hr><ol><li id=fn1 role=doc-endnote><p>Fraassen, B. C. V. (1983).
Calibration: A frequency justification for personal probability. In
<em>Physics, philosophy and psychoanalysis</em> (pp. 295-319). Springer,
Dordrecht.<a href=#fnref1 class=footnote-back role=doc-backlink>↩︎</a></p></li><li id=fn2 role=doc-endnote><p>Hoefer, Carl. (2012). Calibration:
Being in tune with frequencies. dialectica, 66(3):435<a href=#fnref2 class=footnote-back role=doc-backlink>↩︎</a></p></li><li id=fn3 role=doc-endnote><p>Platt, John et al. (1999).
Probabilistic outputs for support vector machines and comparisons to
regularized likelihood methods. Advances in large margin classifiers,
10(3):6<a href=#fnref3 class=footnote-back role=doc-backlink>↩︎</a></p></li><li id=fn4 role=doc-endnote><p>Rahimi, A., Gupta, K., Ajanthan, T.,
Mensink, T., Sminchisescu, C., & Hartley, R. (2020). Post-hoc
calibration of neural networks. <em>arXiv preprint
arXiv:2006.12807</em>.<a href=#fnref4 class=footnote-back role=doc-backlink>↩︎</a></p></li><li id=fn5 role=doc-endnote><p>Rahimi, A., Gupta, K., Ajanthan, T.,
Mensink, T., Sminchisescu, C., & Hartley, R. (2020). Post-hoc
calibration of neural networks. <em>arXiv preprint
arXiv:2006.12807</em>.<a href=#fnref5 class=footnote-back role=doc-backlink>↩︎</a></p></li><li id=fn6 role=doc-endnote><p>Guo, Chuan, Pleiss, Geoff, Sun, Yu
and Weinberger, Kilian Q. (2017). On calibration of modern neural
networks. In International Conference on Machine Learning, pages
1321–13<a href=#fnref6 class=footnote-back role=doc-backlink>↩︎</a></p></li><li id=fn7 role=doc-endnote><p>Naeini, Mahdi Pakdaman, Cooper,
Gregory and Hauskrecht, Milos. (2015). Obtaining well cal- ibrated
probabilities using bayesian binning. In Twenty-Ninth AAAI Conference on
Artificial In- telligence<a href=#fnref7 class=footnote-back role=doc-backlink>↩︎</a></p></li><li id=fn8 role=doc-endnote><p>Zhao, S., Kim, M., Sahoo, R., Ma, T.,
& Ermon, S. (2021). Calibrating predictions to decisions: A novel
approach to multi-class calibration. <em>Advances in Neural Information
Processing Systems</em>, <em>34</em>, 22313-22324.<a href=#fnref8 class=footnote-back role=doc-backlink>↩︎</a></p></li><li id=fn9 role=doc-endnote><p>Zhao, S., Kim, M., Sahoo, R., Ma, T.,
& Ermon, S. (2021). Calibrating predictions to decisions: A novel
approach to multi-class calibration. <em>Advances in Neural Information
Processing Systems</em>, <em>34</em>, 22313-22324.<a href=#fnref9 class=footnote-back role=doc-backlink>↩︎</a></p></li></ol></section></div><div class="row middle-xs"><div class=col-xs-12></div></div><div class=row><div class=col-xs-12><a rel=license href=http://creativecommons.org/licenses/by-nc-nd/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://upload.wikimedia.org/wikipedia/commons/7/73/Cc_by-nc-nd_icon.svg></a></div></div><div style=height:50px></div><div class=site-footer></div></div></div></article><script></script></body></html>