<!doctype html><html lang=en><head><meta charset=utf-8><meta name=generator content="Hugo 0.109.0"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content><meta property="og:url" content="https://qige96.github.io/myblog/posts/review-prob-logic-srl-slp/"><link rel=canonical href=https://qige96.github.io/myblog/posts/review-prob-logic-srl-slp/><link rel=alternate type=application/atom+xml href=https://qige96.github.io/myblogindex.xml title="Blog of Ricky"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/qige96.github.io\/myblog"},"articleSection":"posts","name":"A Review of Probabilistic Logic: SRL - SLP","headline":"A Review of Probabilistic Logic: SRL - SLP","description":"The last SRL theory I would like to introduce here is Stochasitc Logic Program1 (SLP).\nSimilar to Problog, Stochastic Logic Programs is also a probabilistic extesion of classic logic programs. However, SLP is different from Problog, in particular the semantics. So far, the probabilistic logic we had introduced are based on possible world semantics. That is, the probability value assigned to a proposition indicates “the probability of the proposition being true”.","inLanguage":"en-US","author":"","creator":"","publisher":"","accountablePerson":"","copyrightHolder":"","copyrightYear":"2022","datePublished":"2022-07-31 22:39:49 \u002b0100 \u002b0100","dateModified":"2022-07-31 22:39:49 \u002b0100 \u002b0100","url":"https:\/\/qige96.github.io\/myblog\/posts\/review-prob-logic-srl-slp\/","keywords":[]}</script><title>A Review of Probabilistic Logic: SRL - SLP</title><meta property="og:title" content="A Review of Probabilistic Logic: SRL - SLP"><meta property="og:type" content="article"><meta property="og:description" content="The last SRL theory I would like to introduce here is Stochasitc Logic Program1 (SLP).
Similar to Problog, Stochastic Logic Programs is also a probabilistic extesion of classic logic programs. However, SLP is different from Problog, in particular the semantics. So far, the probabilistic logic we had introduced are based on possible world semantics. That is, the probability value assigned to a proposition indicates “the probability of the proposition being true”."><meta name=description content="The last SRL theory I would like to introduce here is Stochasitc Logic Program1 (SLP).
Similar to Problog, Stochastic Logic Programs is also a probabilistic extesion of classic logic programs. However, SLP is different from Problog, in particular the semantics. So far, the probabilistic logic we had introduced are based on possible world semantics. That is, the probability value assigned to a proposition indicates “the probability of the proposition being true”."><meta property="og:locale" content="en-us"><meta property="og:image" content><style>body{font-family:bree serif,sans-serif;-webkit-font-smoothing:antialiased;margin:0 20px}article{max-width:800px;margin-left:auto;margin-right:auto}a{color:#000;text-decoration:none}a:hover{font-weight:600;text-decoration:underline}.post-ads{margin:50px 0}.markdown-body{font-size:18px;max-width:100%}.markdown-body a{text-decoration:underline;text-decoration-color:#000}.markdown-body blockquote{margin:0;padding:0 1em;color:#57606a;border-left:.25em solid #d0d7de}.markdown-body pre{padding:16px;overflow:auto;border-radius:10px}.markdown-body code{padding:.2em .4em;font-size:85%;background-color:#f6f8fa;border-radius:6px}.markdown-body pre>code{padding:0;font-size:100%;background-color:inherit;border:0}.Chinese .markdown-body{line-height:200%}.site-date-catalog{font-size:2rem}.header-title{font-size:2rem;font-weight:700;margin-top:32px;font-family:bungee shade,sans-serif}.header-title a{text-decoration:none}.header-subtitle{color:#666}.header-items{margin:10px 0}.header-item{margin:0 5px}.header-line{width:100%;border-width:2px;border-color:#482936;border-style:solid none none none}.lang-switch{font-weight:600}#posts-list{min-height:600px}.posts-line{font-size:1.2rem;margin:12px 0}.posts-categories{font-size:.8rem;margin:auto;text-align:center}.posts-category{padding:3px 0;border:#000 2px solid;border-radius:5px}.site-footer{margin-top:50px}.site-footer-item{margin-right:12px}.post-content img{max-width:100%;display:block;margin-right:auto;margin-top:12px}.post-header{margin-bottom:50px}.post-title{font-size:2rem;font-weight:600}.post-tags{display:inline;font-weight:600;padding:2px 5px;margin-right:6px;border:#000 2px solid;border-radius:5px}.post-date{font-weight:800;font-style:italic}.post-author{float:right;font-weight:600}.page-content{min-height:60%}.post-content{margin-bottom:50px}.post-content p{hyphens:auto;line-height:1.8;text-justify:ideographic;margin-bottom:1em}.related-content{border-width:3px;border-style:solid;border-color:#000;padding:0 10px;margin-bottom:50px;margin-top:100px}.related-content li{margin:5px 0}.taxonomy-term{font-size:3rem}.gallery-img{text-align:center}.gallery-img span{text-align:center}.gallery-img-desc{font-size:.8em;font-weight:800}#disqus_thread{position:relative}#disqus_thread:after{content:"";display:block;height:55px;width:100%;position:absolute;bottom:0;background:#fff}@media screen and (max-width:600px){.header-title,.header-subtitle,.header-items{text-align:center}.posts-line{font-size:16px}.markdown-body{font-size:16px}.post-title{font-size:2rem}.post-content p{letter-spacing:.05em}}@media screen and (max-width:48em){.posts-category{display:none}}</style><style>.container,.container-fluid{margin-right:auto;margin-left:auto}.container-fluid{padding-right:2rem;padding-left:2rem}.row{box-sizing:border-box;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 1 auto;flex:initial;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-right:-.5rem;margin-left:-.5rem}.row.reverse{-webkit-box-orient:horizontal;-webkit-box-direction:reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse}.col.reverse{-webkit-box-orient:vertical;-webkit-box-direction:reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse}.col-xs,.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9,.col-xs-offset-0,.col-xs-offset-1,.col-xs-offset-10,.col-xs-offset-11,.col-xs-offset-12,.col-xs-offset-2,.col-xs-offset-3,.col-xs-offset-4,.col-xs-offset-5,.col-xs-offset-6,.col-xs-offset-7,.col-xs-offset-8,.col-xs-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-xs{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-xs-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-xs-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-xs-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-xs-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-xs-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-xs-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-xs-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-xs-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-xs-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-xs-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-xs-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-xs-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-xs-offset-0{margin-left:0}.col-xs-offset-1{margin-left:8.33333333%}.col-xs-offset-2{margin-left:16.66666667%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-4{margin-left:33.33333333%}.col-xs-offset-5{margin-left:41.66666667%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-7{margin-left:58.33333333%}.col-xs-offset-8{margin-left:66.66666667%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-10{margin-left:83.33333333%}.col-xs-offset-11{margin-left:91.66666667%}.start-xs{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-xs{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-xs{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-xs{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-xs{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-xs{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-xs{-ms-flex-pack:distribute;justify-content:space-around}.between-xs{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-xs{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-xs{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}@media only screen and (min-width:48em){.container{width:49rem}.col-sm,.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-sm-offset-0,.col-sm-offset-1,.col-sm-offset-10,.col-sm-offset-11,.col-sm-offset-12,.col-sm-offset-2,.col-sm-offset-3,.col-sm-offset-4,.col-sm-offset-5,.col-sm-offset-6,.col-sm-offset-7,.col-sm-offset-8,.col-sm-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-sm{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-sm-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-sm-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-sm-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-sm-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-sm-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-sm-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-sm-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-sm-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-sm-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-sm-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-sm-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-sm-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-sm-offset-0{margin-left:0}.col-sm-offset-1{margin-left:8.33333333%}.col-sm-offset-2{margin-left:16.66666667%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-4{margin-left:33.33333333%}.col-sm-offset-5{margin-left:41.66666667%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-7{margin-left:58.33333333%}.col-sm-offset-8{margin-left:66.66666667%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-10{margin-left:83.33333333%}.col-sm-offset-11{margin-left:91.66666667%}.start-sm{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-sm{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-sm{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-sm{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-sm{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-sm{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-sm{-ms-flex-pack:distribute;justify-content:space-around}.between-sm{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-sm{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-sm{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:64em){.container{width:65rem}.col-md,.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-md-offset-0,.col-md-offset-1,.col-md-offset-10,.col-md-offset-11,.col-md-offset-12,.col-md-offset-2,.col-md-offset-3,.col-md-offset-4,.col-md-offset-5,.col-md-offset-6,.col-md-offset-7,.col-md-offset-8,.col-md-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-md{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-md-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-md-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-md-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-md-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-md-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-md-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-md-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-md-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-md-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-md-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-md-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-md-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-md-offset-0{margin-left:0}.col-md-offset-1{margin-left:8.33333333%}.col-md-offset-2{margin-left:16.66666667%}.col-md-offset-3{margin-left:25%}.col-md-offset-4{margin-left:33.33333333%}.col-md-offset-5{margin-left:41.66666667%}.col-md-offset-6{margin-left:50%}.col-md-offset-7{margin-left:58.33333333%}.col-md-offset-8{margin-left:66.66666667%}.col-md-offset-9{margin-left:75%}.col-md-offset-10{margin-left:83.33333333%}.col-md-offset-11{margin-left:91.66666667%}.start-md{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-md{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-md{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-md{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-md{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-md{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-md{-ms-flex-pack:distribute;justify-content:space-around}.between-md{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-md{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-md{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:75em){.container{width:76rem}.col-lg,.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-lg-offset-0,.col-lg-offset-1,.col-lg-offset-10,.col-lg-offset-11,.col-lg-offset-12,.col-lg-offset-2,.col-lg-offset-3,.col-lg-offset-4,.col-lg-offset-5,.col-lg-offset-6,.col-lg-offset-7,.col-lg-offset-8,.col-lg-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-lg{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-lg-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-lg-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-lg-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-lg-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-lg-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-lg-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-lg-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-lg-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-lg-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-lg-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-lg-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-lg-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-lg-offset-0{margin-left:0}.col-lg-offset-1{margin-left:8.33333333%}.col-lg-offset-2{margin-left:16.66666667%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-4{margin-left:33.33333333%}.col-lg-offset-5{margin-left:41.66666667%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-7{margin-left:58.33333333%}.col-lg-offset-8{margin-left:66.66666667%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-10{margin-left:83.33333333%}.col-lg-offset-11{margin-left:91.66666667%}.start-lg{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-lg{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-lg{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-lg{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-lg{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-lg{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-lg{-ms-flex-pack:distribute;justify-content:space-around}.between-lg{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-lg{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-lg{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}</style><link rel=stylesheet href=https://qige96.github.io/myblog/css/extra.css><link href=https://qige96.github.io/myblog/index.xml rel=alternate type=application/rss+xml title="Blog of Ricky"><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css?family=Bree+Serif|Bungee+Shade" rel=stylesheet><script src=https://qige96.github.io/myblog/js/mathjax-config.js></script>
<script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.6.0/build/styles/default.min.css><script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.6.0/build/highlight.min.js></script>
<script>hljs.highlightAll()</script></head><body><article class=post id=article><div class=row><div class=col-xs-12><div class=site-header><header><div class=header-title><a href=https://qige96.github.io/myblog/>My Sketch Pad</a></div><div class=header-subtitle></div></header><div class="row end-md center-xs header-items"></div><div class="row end-xs"></div><div class=header-line></div></div><header class=post-header><h1 class=post-title>A Review of Probabilistic Logic: SRL - SLP</h1><div class="row post-desc"><div class=col-xs-6><time class=post-date datetime="2022-07-31 22:39:49 +0100">31 Jul 2022</time></div><div class=col-xs-6></div></div></header><div class="post-content markdown-body"><p>The last SRL theory I would like to introduce here is Stochasitc
Logic Program<a href=#fn1 class=footnote-ref id=fnref1 role=doc-noteref><sup>1</sup></a> (SLP).</p><p>Similar to Problog, Stochastic Logic Programs is also a probabilistic
extesion of classic logic programs. However, SLP is different from
Problog, in particular the semantics. So far, the probabilistic logic we
had introduced are based on possible world semantics. That is, the
probability value assigned to a proposition indicates “the probability
of the proposition being true”. While in SLP, the probability value
assigned to a proposition indicates “the probability of a proposition
being selected in one step of a proof”. Therefore, we cannot directly
apply SLP to our central question, but need some prepocessing jobs.</p><p>Below is an example of how a Stochastic Logic Program looks like</p><div class=sourceCode id=cb1><pre class="sourceCode prolog"><code class="sourceCode prolog"><span id=cb1-1><a href=#cb1-1 aria-hidden=true tabindex=-1></a><span class=fl>0.3</span><span class=fu>:</span>p(a)<span class=kw>.</span></span>
<span id=cb1-2><a href=#cb1-2 aria-hidden=true tabindex=-1></a><span class=fl>0.7</span><span class=fu>:</span>p(b)<span class=kw>.</span></span>
<span id=cb1-3><a href=#cb1-3 aria-hidden=true tabindex=-1></a><span class=fl>0.2</span><span class=fu>:</span>q(a)<span class=kw>.</span></span>
<span id=cb1-4><a href=#cb1-4 aria-hidden=true tabindex=-1></a><span class=fl>0.8</span><span class=fu>:</span>q(b)<span class=kw>.</span></span>
<span id=cb1-5><a href=#cb1-5 aria-hidden=true tabindex=-1></a><span class=fl>0.4</span><span class=fu>:</span>s(<span class=dt>X</span>) <span class=kw>:-</span> p(<span class=dt>X</span>)<span class=kw>,</span> <span class=dt>P</span>(<span class=dt>X</span>)<span class=kw>.</span></span>
<span id=cb1-6><a href=#cb1-6 aria-hidden=true tabindex=-1></a><span class=fl>0.6</span><span class=fu>:</span>s(<span class=dt>X</span>) <span class=kw>:-</span> q(<span class=dt>X</span>)<span class=kw>.</span></span></code></pre></div><p>In the above example, we see similar syntax as Problog: there are
facts and rules, and probabilities. A significant differences is, in
Problog, rules are deterministic, but in SLP, rules can be assigned with
parameters. What’s more, another requirement of SLP is that the
parameters of clauses whose heads share the same predicate symbol sum to
one. In the abve example, we can see line 1 and line 2 share the same
predicate symbol <em>p</em>, line 3 and line 4 share <em>q</em>, and the
heads of line 5 and line 6 share the same predicate symbol <em>s</em>.
Such kind of program, where every clause is assigned with a parameter
value, and the parameters of clauses whose heads share the same
predicate symbol sum to one, is called pure normalised SLP, and the
parameters can be regarded as probabilities. There are SLPs of which not
every clause is assigne a parameter, and the parameter may not sum to 1.
These SLPs are impure, and unnormalised. We focus on pure, normalised
SLPs because they are simple, and usually, impure unnormalised SLPs can
be converted into pure, normalised ones. In Poblog, it is no problem to
have both <span class="math inline">\(0.9::p(a). \ 0.9::p(b)\)</span>.
However, in pure normalised SLP, it is not allowed because <span class="math inline">\(p(a), \ p(b)\)</span> is the head of the clause,
and share the same predicate symbol. The probabilities of <span class="math inline">\(p(a), \ p(b)\)</span> must sum to 1.</p><p>With an pure normalised SLP, we can use it to calculate the
probability of a derived conclusion (that is derivable from that SLP).
For instance, given the above example SLP, what’s the probability of
<span class="math inline">\(s(X)\)</span>? Syntactally, this problem
takes the form of</p><p><span class="math display">\[
\phi_1^{X_1},\dots,\phi_n^{X_n}|\!\!\!\approx \psi^Y
\]</span></p><p>This looks the same as our central question. But we should bear in
mind that the resulting probability <span class="math inline">\(Y\)</span> is not indicating the probability of
the conclusion <span class="math inline">\(\psi\)</span> being correct,
but the probability of the conclusion <span class="math inline">\(\psi\)</span> being .</p><p>To compute <span class="math inline">\(Y\)</span> is simple. We first
prove the query <span class="math inline">\(\psi\)</span>. There might
be multiple feasible proofs. <span class="math inline">\(Y\)</span> is
the sum of the probabilities of all the feasible proofs to <span class="math inline">\(\psi\)</span>. One proof to <span class="math inline">\(\psi\)</span> is a sequence of selecting the
applicable clauses in the SLP. Each selection is a stochastic choice
according to the assigned probabilities. The probability of a proof is
the product of the probabilities of these selections. All the proofs can
be organised as a proof tree. Below is an illusration using the above
example SLP to prove the query <span class="math inline">\(s(X)\)</span>. In the tree, every path from the
root node to a leaf node is a proof, whether successful or failed. Here,
we examine the rightmost path: to prove <span class="math inline">\(s(X)\)</span>, selecting line, 6 we need to prove
<span class="math inline">\(q(X)\)</span></p><figure><img src=https://qige96.github.io/myblog/images/SLP-tree.png alt="SLP tree"><figcaption aria-hidden=true>SLP tree</figcaption></figure><p>Formally, we say the successful proof, i.e., the path ended with
<span class="math inline">\(\square\)</span>, to be a refutation,
denoted as <span class="math inline">\(r = \langle c_i, ..., c_j
\rangle\)</span>, a sequence of selected clauses. Then, all the feasible
proofs of a query is denoted as <span class="math inline">\(R(G)\)</span> where <span class="math inline">\(G\)</span> is the query, or the Goal of the
proofs. Then, given a Stochastic Logic Program <span class="math inline">\(S\)</span> and a goal <span class="math inline">\(G\)</span>, the probability distribution over the
refutations is defined as</p><p><span class="math display">\[
P_{S,G}(r) = \frac{\prod_{c \in r} p_c}{Z}
\]</span></p><p>where <span class="math inline">\(Z = \sum_{r \in R(G)} \prod_{c \in
r} p_c\)</span> is just a normalising constant.</p><p>We know that the probabilities of SLP have different meanings of
Problog, and other probabilistic logics introuced before. Then, where
can we apply SLP?</p><p>Though the probabilities of clauses in a SLP are not saying the
correctness or truth for that clause, we can derive those probabilities
of this meaning. The key idea is to regard the body of a clause as an
explanation of the head<a href=#fn2 class=footnote-ref id=fnref2 role=doc-noteref><sup>2</sup></a>. For example, here is a simple
SLP:</p><div class=sourceCode id=cb2><pre class="sourceCode prolog"><code class="sourceCode prolog"><span id=cb2-1><a href=#cb2-1 aria-hidden=true tabindex=-1></a><span class=fl>0.6</span><span class=fu>:</span>s(<span class=dt>X</span>) <span class=kw>:-</span> p(<span class=dt>X</span>)<span class=kw>.</span></span>
<span id=cb2-2><a href=#cb2-2 aria-hidden=true tabindex=-1></a><span class=fl>0.4</span><span class=fu>:</span>s(<span class=dt>X</span>) <span class=kw>:-</span> q(<span class=dt>X</span>)<span class=kw>.</span></span></code></pre></div><p>In this simple SLP, we see 3 predicate symbols <span class="math inline">\(s, p, q\)</span>, and one variable <span class="math inline">\(X\)</span>. Suppose the domain of this SLP is two
constants <span class="math inline">\(\{a, b\}\)</span>, and <span class="math inline">\(Pr[s(a)] = 0.8, \ Pr[s(b)] = 0.2\)</span> what’s
the probability of <span class="math inline">\(p(a), p(b), q(a),
q(b)\)</span>?</p><p>If we observed <span class="math inline">\(s(a)\)</span> occur, then
by line 1, we have an explanation that “<span class="math inline">\(s(a)\)</span> orrur because <span class="math inline">\(p(a)\)</span> occur”, with probability 0.6. By
Closed World Assumption, we also have <span class="math inline">\(\neg
q(a)\)</span> because <span class="math inline">\(q(a)\)</span> is not
explicitly stated. Thus, we have the following conditinal probability
<span class="math inline">\(Pr[p(a), \neg q(a)|s(a)] = 0.6\)</span></p><p>Similarly, we have</p><p><span class="math display">\[
Pr[\neg p(a), q(a)|s(a)] = 0.4
\]</span></p><p><span class="math display">\[
Pr[p(a), q(a)|s(a)] = 0
\]</span></p><p><span class="math display">\[
Pr[p(b), \neg q(b)|s(b)] = 0.4
\]</span></p><p><span class="math display">\[
Pr[\neg p(b), q(b)|s(b)] = 0.6
\]</span></p><p><span class="math display">\[
Pr[\neg p(b), q(b)|s(b)] = 0
\]</span></p><p>And thus:</p><p><span class="math display">\[
Pr[p(a), \neg q(a), s(a)] = Pr[p(a), \neg q(a)| s(a)] * Pr[s(a)] =
0.6*0.8=0.48
\]</span></p><p><span class="math display">\[
Pr[\neg p(a), q(a), s(a)] = Pr[\neg p(a), q(a)| s(a)] * Pr[s(a)] =
0.4*0.8=0.32
\]</span></p><p><span class="math display">\[
Pr[p(a), \neg q(b), s(b)] = Pr[p(b), \neg q(b)| s(b)] * Pr[s(b)] =
0.6*0.2=0.12
\]</span></p><p><span class="math display">\[
Pr[\neg p(b), q(b), s(b)] = Pr[\neg p(b), q(b)| s(b)] * Pr[s(b)] =
0.4*0.2=0.08
\]</span></p><section id=footnotes class="footnotes footnotes-end-of-document" role=doc-endnotes><hr><ol><li id=fn1><p>Cussens, J. <em>Parameter Estimation in Stochastic Logic
Programs</em>. Machine Learning 44, 245–271 (2001). <a href=https://doi.org/10.1023/A:1010924021315>https://doi.org/10.1023/A:1010924021315</a><a href=#fnref1 class=footnote-back role=doc-backlink>↩︎</a></p></li><li id=fn2><p>Chen, J., Muggleton, S. & Santos, J. <em>Learning
probabilistic logic models from probabilistic examples</em>. Mach
Learn 73, 55–85 (2008). <a href=https://doi.org/10.1007/s10994-008-5076-4>https://doi.org/10.1007/s10994-008-5076-4</a><a href=#fnref2 class=footnote-back role=doc-backlink>↩︎</a></p></li></ol></section></div><div class="row middle-xs"><div class=col-xs-12></div></div><div class=row><div class=col-xs-12><a rel=license href=http://creativecommons.org/licenses/by-nc-nd/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://upload.wikimedia.org/wikipedia/commons/7/73/Cc_by-nc-nd_icon.svg></a></div></div><div style=height:50px></div><div class=site-footer></div></div></div></article><script></script></body></html>