<!doctype html><html lang=en><head><meta charset=utf-8><meta name=generator content="Hugo 0.104.3"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content><meta property="og:url" content="https://qige96.github.io/myblog/posts/review-prob-logic-gofpl-bacchus/"><link rel=canonical href=https://qige96.github.io/myblog/posts/review-prob-logic-gofpl-bacchus/><link rel=alternate type=application/atom+xml href=https://qige96.github.io/myblogindex.xml title="Blog of Ricky"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/qige96.github.io\/myblog"},"articleSection":"posts","name":"A Review of Probabilistic Logic: GOFPL - Bacchus","headline":"A Review of Probabilistic Logic: GOFPL - Bacchus","description":"So far, we reviewed two probabilistic logic theories: Nilsson’s Probabilistic Logic and Bundy’s Incidence Calculus. However, within these logics, we can only use probability at a meta-level, but cannot talk about probability within the logic. Like example 2.1, with the three propositions \\(\\{rainy, sunny, windy\\}\\), we can only talk about \\(\\neg windy \\land rainy\\) or \\((sunny \\lor windy) \\land \\neg rainy\\), and compute their probabilities, but not the relations between the probabilities of them, such as “the probability of rainy is less than that of sunny”.","inLanguage":"en-US","author":"","creator":"","publisher":"","accountablePerson":"","copyrightHolder":"","copyrightYear":"2022","datePublished":"2022-07-31 20:46:07 \u002b0100 \u002b0100","dateModified":"2022-07-31 20:46:07 \u002b0100 \u002b0100","url":"https:\/\/qige96.github.io\/myblog\/posts\/review-prob-logic-gofpl-bacchus\/","keywords":[]}</script><title>A Review of Probabilistic Logic: GOFPL - Bacchus</title><meta property="og:title" content="A Review of Probabilistic Logic: GOFPL - Bacchus"><meta property="og:type" content="article"><meta property="og:description" content="So far, we reviewed two probabilistic logic theories: Nilsson’s Probabilistic Logic and Bundy’s Incidence Calculus. However, within these logics, we can only use probability at a meta-level, but cannot talk about probability within the logic. Like example 2.1, with the three propositions \(\{rainy, sunny, windy\}\), we can only talk about \(\neg windy \land rainy\) or \((sunny \lor windy) \land \neg rainy\), and compute their probabilities, but not the relations between the probabilities of them, such as “the probability of rainy is less than that of sunny”."><meta name=description content="So far, we reviewed two probabilistic logic theories: Nilsson’s Probabilistic Logic and Bundy’s Incidence Calculus. However, within these logics, we can only use probability at a meta-level, but cannot talk about probability within the logic. Like example 2.1, with the three propositions \(\{rainy, sunny, windy\}\), we can only talk about \(\neg windy \land rainy\) or \((sunny \lor windy) \land \neg rainy\), and compute their probabilities, but not the relations between the probabilities of them, such as “the probability of rainy is less than that of sunny”."><meta property="og:locale" content="en-us"><meta property="og:image" content><style>body{font-family:bree serif,sans-serif;-webkit-font-smoothing:antialiased;margin:0 20px}article{max-width:800px;margin-left:auto;margin-right:auto}a{color:#000;text-decoration:none}a:hover{font-weight:600;text-decoration:underline}.post-ads{margin:50px 0}.markdown-body{font-size:18px;max-width:100%}.markdown-body a{text-decoration:underline;text-decoration-color:#000}.markdown-body blockquote{margin:0;padding:0 1em;color:#57606a;border-left:.25em solid #d0d7de}.markdown-body pre{padding:16px;overflow:auto;border-radius:10px}.markdown-body code{padding:.2em .4em;font-size:85%;background-color:#f6f8fa;border-radius:6px}.markdown-body pre>code{padding:0;font-size:100%;background-color:inherit;border:0}.Chinese .markdown-body{line-height:200%}.site-date-catalog{font-size:2rem}.header-title{font-size:2rem;font-weight:700;margin-top:32px;font-family:bungee shade,sans-serif}.header-title a{text-decoration:none}.header-subtitle{color:#666}.header-items{margin:10px 0}.header-item{margin:0 5px}.header-line{width:100%;border-width:2px;border-color:#482936;border-style:solid none none none}.lang-switch{font-weight:600}#posts-list{min-height:600px}.posts-line{font-size:1.2rem;margin:12px 0}.posts-categories{font-size:.8rem;margin:auto;text-align:center}.posts-category{padding:3px 0;border:#000 2px solid;border-radius:5px}.site-footer{margin-top:50px}.site-footer-item{margin-right:12px}.post-content img{max-width:100%;display:block;margin-right:auto;margin-top:12px}.post-header{margin-bottom:50px}.post-title{font-size:2rem;font-weight:600}.post-tags{display:inline;font-weight:600;padding:2px 5px;margin-right:6px;border:#000 2px solid;border-radius:5px}.post-date{font-weight:800;font-style:italic}.post-author{float:right;font-weight:600}.page-content{min-height:60%}.post-content{margin-bottom:50px}.post-content p{hyphens:auto;line-height:1.8;text-justify:ideographic;margin-bottom:1em}.related-content{border-width:3px;border-style:solid;border-color:#000;padding:0 10px;margin-bottom:50px;margin-top:100px}.related-content li{margin:5px 0}.taxonomy-term{font-size:3rem}.gallery-img{text-align:center}.gallery-img span{text-align:center}.gallery-img-desc{font-size:.8em;font-weight:800}#disqus_thread{position:relative}#disqus_thread:after{content:"";display:block;height:55px;width:100%;position:absolute;bottom:0;background:#fff}@media screen and (max-width:600px){.header-title,.header-subtitle,.header-items{text-align:center}.posts-line{font-size:16px}.markdown-body{font-size:16px}.post-title{font-size:2rem}.post-content p{letter-spacing:.05em}}@media screen and (max-width:48em){.posts-category{display:none}}</style><style>.container,.container-fluid{margin-right:auto;margin-left:auto}.container-fluid{padding-right:2rem;padding-left:2rem}.row{box-sizing:border-box;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 1 auto;flex:initial;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-right:-.5rem;margin-left:-.5rem}.row.reverse{-webkit-box-orient:horizontal;-webkit-box-direction:reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse}.col.reverse{-webkit-box-orient:vertical;-webkit-box-direction:reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse}.col-xs,.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9,.col-xs-offset-0,.col-xs-offset-1,.col-xs-offset-10,.col-xs-offset-11,.col-xs-offset-12,.col-xs-offset-2,.col-xs-offset-3,.col-xs-offset-4,.col-xs-offset-5,.col-xs-offset-6,.col-xs-offset-7,.col-xs-offset-8,.col-xs-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-xs{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-xs-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-xs-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-xs-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-xs-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-xs-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-xs-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-xs-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-xs-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-xs-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-xs-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-xs-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-xs-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-xs-offset-0{margin-left:0}.col-xs-offset-1{margin-left:8.33333333%}.col-xs-offset-2{margin-left:16.66666667%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-4{margin-left:33.33333333%}.col-xs-offset-5{margin-left:41.66666667%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-7{margin-left:58.33333333%}.col-xs-offset-8{margin-left:66.66666667%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-10{margin-left:83.33333333%}.col-xs-offset-11{margin-left:91.66666667%}.start-xs{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-xs{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-xs{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-xs{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-xs{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-xs{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-xs{-ms-flex-pack:distribute;justify-content:space-around}.between-xs{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-xs{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-xs{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}@media only screen and (min-width:48em){.container{width:49rem}.col-sm,.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-sm-offset-0,.col-sm-offset-1,.col-sm-offset-10,.col-sm-offset-11,.col-sm-offset-12,.col-sm-offset-2,.col-sm-offset-3,.col-sm-offset-4,.col-sm-offset-5,.col-sm-offset-6,.col-sm-offset-7,.col-sm-offset-8,.col-sm-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-sm{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-sm-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-sm-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-sm-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-sm-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-sm-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-sm-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-sm-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-sm-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-sm-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-sm-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-sm-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-sm-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-sm-offset-0{margin-left:0}.col-sm-offset-1{margin-left:8.33333333%}.col-sm-offset-2{margin-left:16.66666667%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-4{margin-left:33.33333333%}.col-sm-offset-5{margin-left:41.66666667%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-7{margin-left:58.33333333%}.col-sm-offset-8{margin-left:66.66666667%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-10{margin-left:83.33333333%}.col-sm-offset-11{margin-left:91.66666667%}.start-sm{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-sm{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-sm{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-sm{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-sm{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-sm{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-sm{-ms-flex-pack:distribute;justify-content:space-around}.between-sm{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-sm{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-sm{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:64em){.container{width:65rem}.col-md,.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-md-offset-0,.col-md-offset-1,.col-md-offset-10,.col-md-offset-11,.col-md-offset-12,.col-md-offset-2,.col-md-offset-3,.col-md-offset-4,.col-md-offset-5,.col-md-offset-6,.col-md-offset-7,.col-md-offset-8,.col-md-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-md{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-md-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-md-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-md-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-md-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-md-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-md-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-md-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-md-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-md-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-md-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-md-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-md-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-md-offset-0{margin-left:0}.col-md-offset-1{margin-left:8.33333333%}.col-md-offset-2{margin-left:16.66666667%}.col-md-offset-3{margin-left:25%}.col-md-offset-4{margin-left:33.33333333%}.col-md-offset-5{margin-left:41.66666667%}.col-md-offset-6{margin-left:50%}.col-md-offset-7{margin-left:58.33333333%}.col-md-offset-8{margin-left:66.66666667%}.col-md-offset-9{margin-left:75%}.col-md-offset-10{margin-left:83.33333333%}.col-md-offset-11{margin-left:91.66666667%}.start-md{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-md{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-md{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-md{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-md{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-md{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-md{-ms-flex-pack:distribute;justify-content:space-around}.between-md{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-md{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-md{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:75em){.container{width:76rem}.col-lg,.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-lg-offset-0,.col-lg-offset-1,.col-lg-offset-10,.col-lg-offset-11,.col-lg-offset-12,.col-lg-offset-2,.col-lg-offset-3,.col-lg-offset-4,.col-lg-offset-5,.col-lg-offset-6,.col-lg-offset-7,.col-lg-offset-8,.col-lg-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-lg{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-lg-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-lg-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-lg-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-lg-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-lg-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-lg-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-lg-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-lg-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-lg-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-lg-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-lg-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-lg-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-lg-offset-0{margin-left:0}.col-lg-offset-1{margin-left:8.33333333%}.col-lg-offset-2{margin-left:16.66666667%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-4{margin-left:33.33333333%}.col-lg-offset-5{margin-left:41.66666667%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-7{margin-left:58.33333333%}.col-lg-offset-8{margin-left:66.66666667%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-10{margin-left:83.33333333%}.col-lg-offset-11{margin-left:91.66666667%}.start-lg{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-lg{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-lg{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-lg{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-lg{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-lg{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-lg{-ms-flex-pack:distribute;justify-content:space-around}.between-lg{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-lg{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-lg{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}</style><link rel=stylesheet href=https://qige96.github.io/myblog/css/extra.css><link href=https://qige96.github.io/myblog/index.xml rel=alternate type=application/rss+xml title="Blog of Ricky"><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css?family=Bree+Serif|Bungee+Shade" rel=stylesheet><script src=https://qige96.github.io/myblog/js/mathjax-config.js></script>
<script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.6.0/build/styles/default.min.css><script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.6.0/build/highlight.min.js></script>
<script>hljs.highlightAll()</script></head><body><article class=post id=article><div class=row><div class=col-xs-12><div class=site-header><header><div class=header-title><a href=https://qige96.github.io/myblog/>My Sketch Pad</a></div><div class=header-subtitle></div></header><div class="row end-md center-xs header-items"></div><div class="row end-xs"></div><div class=header-line></div></div><header class=post-header><h1 class=post-title>A Review of Probabilistic Logic: GOFPL - Bacchus</h1><div class="row post-desc"><div class=col-xs-6><time class=post-date datetime="2022-07-31 20:46:07 +0100">31 Jul 2022</time></div><div class=col-xs-6></div></div></header><div class="post-content markdown-body"><p>So far, we reviewed two probabilistic logic theories: Nilsson’s
Probabilistic Logic and Bundy’s Incidence Calculus. However, within
these logics, we can only use probability at a meta-level, but cannot
talk about probability within the logic. Like example 2.1, with the
three propositions <span class="math inline">\(\{rainy, sunny,
windy\}\)</span>, we can only talk about <span class="math inline">\(\neg windy \land rainy\)</span> or <span class="math inline">\((sunny \lor windy) \land \neg rainy\)</span>, and
compute their probabilities, but not the <strong>relations between the
probabilities of them</strong>, such as “the probability of rainy is
less than that of sunny”. In Fahiem Bacchus’ Lp, a probability operator
is explicitly introduced as a primitive, so that we can talk about
probability within the language, such as <span class="math inline">\(prob(rainy) &lt; prob(sunny)\)</span>.</p><p>Lp is such a first-order probabilistic language that is designed to
express rich information, not only relations among objects but also
relations among probabilities of objects. Bacchus also proposed a
corresponding proof system for the language, consisting of axioms and
inference rules. Personally speaking, I consider Lp to be a
sophisticated theory that can do far more than solving our “central
question”, and the cost is the representation and reasoning complexity.
Only use Lp when necessary. Using Lp to merely address the central
question would be an overkill.</p><p>First-order logic is the foundation of classical logic theory. I
assume the readers are familiar with it, including the syntax,
semantics, and proof theory. Here is just a quick comparison between
propositional logic and first-order logic: propositional logic only
defines the relation among propositions <span class="math inline">\(\{\phi_1, \phi_2, ..., \phi_n \}\)</span> using
connectives like <span class="math inline">\(\land,
\rightarrow\)</span>, while first-order logic extends propositional
logic but defines what constitutes a proposition. Therefore, in
first-order logic, we can see more elements, including functions,
predicates, quantifiers, variables, and constants. Below is an example
showing how knowledge can be represented by first-order logic:</p><p><span class="math display">\[
\begin{align*}& \phi_1 = student(Jane) \\& \phi_2 =
student(Jane) \land from(jane, School\_A) \\& \phi_3 =
\forall{x}.[student(x) \land from(x, School\_A) \rightarrow
female(x)]\end{align*}
\]</span></p><p>Proposition <span class="math inline">\(\phi_1\)</span> says “Jane is
a student”. Proposition <span class="math inline">\(\phi_2\)</span> says
“Jane is a student from school A”. Proposition <span class="math inline">\(\phi_3\)</span> says “All students from school A
are female”. The three propositions have an inner structure. They are
constituted by constants (<span class="math inline">\(Jane,
School\_A\)</span>), variables (<span class="math inline">\(x\)</span>),
predicates (<span class="math inline">\(student/1, from/2,
female/1\)</span>), and quantifiers (<span class="math inline">\(\forall\)</span>). These propositions are unlike
those in previous examples 1.1, 1.2, and 2.1. Very generally speaking,
first-order logic constitutes propositions by asserting relations
(predicates) among a set of objects (variables, functions, and
constants).</p><p>Assigning probability to first-order logical propositions could be
problematic. It is OK to assign and process probabilities to <span class="math inline">\(\phi_1\)</span> and <span class="math inline">\(\phi_2\)</span> as we did in Probabilistic Logic
or Incidence Calculus. Supposed that <span class="math inline">\(Pr(\phi_1) = 0.8\)</span>, we can interpret it as
“there are a number of possible worlds of equal probability, and in 80%
of these possible worlds, Jane is a student”.</p><p>But when it comes to <span class="math inline">\(\phi_3\)</span>, we
meet the first question: what does <span class="math inline">\(Pr(\phi_3) = 0.8\)</span> mean? Recall that <span class="math inline">\(\phi_3\)</span> says “All students from school A
are female”, then we can have at least two meanings of <span class="math inline">\(Pr(\phi_3)\)</span></p><ol type=1><li>“There are a number of possible worlds of equal probability, and in
80% of these worlds, all students from school A are female”</li><li>“In this real world, 80% of the students from school A are female”
We can see the differences between the two interpretations. The former
imagines multiple possible worlds, while the latter doesn’t bother the
possible worlds. When our propositions involve relations among multiple
objects, we can interpret probability as proportion or frequency.
Correspondingly, when our propositions only state properties of one
object or assertions of one special, non-recurrent event, we usually
interpret probability as the degree of belief.</li></ol><p>We need to distinguish different types of probabilities. Yes, we have
almost no controversy about how probabilities behave, which is defined
by probability axioms. However, we are not sure about what on earth
probability is. Some argue that probability is just proportion or
frequency that reflects objective properties of the real world, while
some claim that probability is the degree of belief that reflects the
subjective state of our mind. Some suggest that the two types of
probabilities are essentially the same thing, while some think that they
are different. The main argument seems whether the probability is
objective or subjective, or how much objective and how much subjective.
I’ve ever seen 6 interpretations of probability lie in different
locations of this objective-subjective spectrum, and I am sure there
should be more than 6 in the mathematical and philosophical
literature.</p><p>If they are not the same thing, the subsequent problem becomes, can
they be connected? We know that though computers represent integers and
floating numbers in different ways, they are still numbers and we still
can add 1 with 1.5 to 2.5. Nevertheless, if 1 means the length of an
item and 1.5 means the weight of another item, then adding the two
numbers produce meaningless results. If the frequency probability and
the degree of belief probability are different things, can we add or
multiply the two types of probabilities? There is still no agreement and
the discussion shall go on in the future.</p><p>Coming back to Bacchus’ Lp. Bacchus called the two types of
probabilities <em>statistical probability</em> and <em>propositional
probability</em>. He didn’t claim that one interpretation is better than
the other. He just pointed out that previous work did not distinguish
the two types of probabilities, and they consider mostly propositional
probability. Therefore, Bacchus designed his own probabilistic logic Lp
to better represent and reason statistical probability.</p><p>The focus of Bacchus is not the central question we put in the
Introduction. Bacchus aimed to propose a language that can better
represent the assertions of statistical information and degree of
belief. He firstly propose two separate languages for both types of
assertions respectively, and lastly came up with a unified language.
Hence, the main content of Bacchus’ work is not about algorithms to
calculate probabilities, but the formalism and proof system to represent
and reason uncertain knowledge.</p><p>Now I will present the logic for propositional probability in detail.
The logic for statistical probability is very similar to the
propositional one.</p><h3 id=propositional-probabilistic-representation-and-reasoning>Propositional
Probabilistic Representation and Reasoning</h3><p>Following the convention of introducing first-order logic, we present
the syntax, semantics, and proof system of Lp.</p><p><strong>Syntax</strong></p><p>Below are the symbols allowed to use when writing assertions in
<strong>Lp.</strong></p><ul><li><p>A set of n-ary function symbols <span class="math inline">\(f, g,
h,...\)</span>. Conventionally, constants are 0-ary function
symbols.</p></li><li><p>A set of n-ary predicate symbols <span class="math inline">\(P,Q,R,...\)</span></p></li><li><p>A set of object variables and numeric variables <span class="math inline">\(x, y, z,...\)</span></p></li><li><p>The connectives <span class="math inline">\(\land\)</span> and
<span class="math inline">\(\neg\)</span></p></li><li><p>The quantifier <span class="math inline">\(\forall\)</span> The
above symbols are the same in the definition of ordinary first-order
logic. Yet Lp is not ordinary first-order logic, it supports the
expression of probability knowledge, so it introduces the following
extra primitive symbols as part of the language itself:</p></li><li><p>The binary object predicate symbol <span class="math inline">\(=\)</span>. It returns <span class="math inline">\(True\)</span> if the two objects are the same
object.</p></li><li><p>The binary numeric predicate symbols <span class="math inline">\(&lt;\)</span>, <span class="math inline">\(=\)</span>, and the binary numeric function
symbols <span class="math inline">\(+\)</span> and <span class="math inline">\(*\)</span></p></li><li><p>The sentential probability operator <span class="math inline">\(prob\)</span>. It returns the propositional
probability of a logical formula. A formula of Lp is a string of allowed
symbols satisfying the following rules:</p></li><li><p>a single object variable or constant is an <em>o-term</em>, a
singe numeric variable or constant is an <em>f-term</em>.</p></li><li><p>If <span class="math inline">\(f\)</span> is an n-ary object
function symbol, and <span class="math inline">\(t_1, ...,t_n\)</span>
are o-terms, then <span class="math inline">\(f(t_1, ..., t_n)\)</span>
is also an o-term. If <span class="math inline">\(\boldsymbol
f\)</span> is an n-ary numeric function symbol, and <span class="math inline">\(\boldsymbol{t_1, ...,t_n}\)</span> are f-terms,
then <span class="math inline">\(\boldsymbol{f(t_1, ..., t_n)}\)</span>
is also an f-term.</p></li><li><p>If <span class="math inline">\(P\)</span> is an n-ary object
predicate symbol, and <span class="math inline">\(t_1, ...,t_n\)</span>
are o-terms, then <span class="math inline">\(P(t_1, ..., t_n)\)</span>
is a formula. If <span class="math inline">\(\boldsymbol P\)</span> is
an n-ary numeric predicate symbol, and <span class="math inline">\(\boldsymbol{t_1, ...,t_n}\)</span> are f-terms,
then <span class="math inline">\(\boldsymbol{P(t_1, ..., t_n)}\)</span>
is a formula.</p></li><li><p>If <span class="math inline">\(\alpha\)</span>is a formula, then
so is <span class="math inline">\(\neg\alpha\)</span></p></li><li><p>If <span class="math inline">\(\alpha\)</span>and <span class="math inline">\(\beta\)</span> are formulas, then so is <span class="math inline">\(\alpha \land \beta\)</span></p></li><li><p>If <span class="math inline">\(\alpha\)</span>is a formula and
<span class="math inline">\(x\)</span>is a numeric or object variable,
then so is <span class="math inline">\(\forall{x}.\alpha\)</span></p></li><li><p>if <span class="math inline">\(\alpha\)</span>is a formula, then
<span class="math inline">\(prob(\alpha)\)</span> is an f-term The last
rule of formation provides native support for constructing f-terms from
existent formulas.</p></li></ul><p><strong>Semantics</strong></p><p>For propositional probabilistic formulas, we interpret them via
possible world semantics, as what we did in Probabilistic Logic and
Incidence Calculus: assigning (propositional) probabilities to possible
worlds, and then assigning possible worlds to formulas. The difference
in Lp is that we work for first-order logic, and support assertions
about probability, so the semantics will be more complicated. To
interpret a formula in our language, we define such a structure:</p><p><span class="math display">\[
M=\langle \mathcal{O}, S,\mathscr{v}, \mu \rangle
\]</span></p><p>where</p><ul><li><p><span class="math inline">\(\mathcal{O}\)</span>is a set of
objects of the domain one wish to describe</p></li><li><p><span class="math inline">\(S\)</span> is a set of possible
worlds, or states</p></li><li><p><span class="math inline">\(\mathscr{v}\)</span> is a function
that maps a possible world to an interpretation</p></li><li><p><span class="math inline">\(\mu\)</span> is a probability
function over possible worlds <span class="math inline">\(\mu : S
\rightarrow [0,1]\)</span> and <span class="math inline">\(\sum_{s \in
S} \mu(s) = 1\)</span> We use the following rules to interpret a
formula</p></li><li><p>is <span class="math inline">\(x\)</span> is a variable, then the
variable assignment determines the interpretation of the variable <span class="math inline">\(x^{(M, v)}=v(x)\)</span></p></li><li><p>If <span class="math inline">\(f\)</span> is an n-ary function
symbol, and <span class="math inline">\(t_1, ...,t_n\)</span> are terms
of the same type (either object or numeric), then <span class="math inline">\([f(t_1,...,t_n)]^{(M, v)} =
f^{\mathscr{v}}(t_1^{(M, v)}, ..., t_n^{(M, v)})\)</span></p></li><li><p>If <span class="math inline">\(P\)</span> is an n-ary predicate
symbol, and <span class="math inline">\(t_1, ...,t_n\)</span> are terms
of the same type (either object or numeric), then <span class="math inline">\((M,s,v)\vDash P(t_1,...,t_n) \quad iff \quad
\langle t_1^{(M, v)}, ..., t_n^{(M, v)} \rangle \in
P^{\mathscr{v}(s)}\)</span></p></li><li><p>If <span class="math inline">\(s\)</span> and <span class="math inline">\(t\)</span> are terms of the same type, then <span class="math inline">\((M, v) \vDash (s=t) \quad iff \quad s^{(M, v)} =
t^{(M, v)}\)</span></p></li><li><p>For every formula <span class="math inline">\(\alpha\)</span>, we
have <span class="math inline">\((M,s, v) \vDash (\neg \alpha) \quad iff
\quad (M.S.v) \nvDash \alpha\)</span></p></li><li><p>For every pair of formulas <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, we have <span class="math inline">\((M,s, v) \vDash (\alpha \land \beta) \quad iff
\quad (M.S.v) \vDash \alpha \quad and \quad (M.S.v) \vDash
\beta\)</span></p></li><li><p>For every formula <span class="math inline">\(\alpha\)</span> and
object variable <span class="math inline">\(x\)</span>, we have <span class="math inline">\((M,s,v) \vDash \forall{x}.\alpha \quad iff \quad
(M.S.v[x/o]) \vDash \alpha \quad for \ all \ o \in
\mathcal{O}\)</span> where <span class="math inline">\(v[x/o]\)</span> is the variable assignment
function identical to <span class="math inline">\(v\)</span> except that
it maps the variable <span class="math inline">\(x\)</span> to the
individual <span class="math inline">\(o\)</span></p></li><li><p>For every formula <span class="math inline">\(\alpha\)</span> and
numeric variable <span class="math inline">\(r\)</span>, we have <span class="math inline">\((M,s,v) \vDash \forall{x}.\alpha \quad iff \quad
(M.S.v[x/o]) \vDash \alpha \quad for \ all \ r \in
\mathbb{R}\)</span> where <span class="math inline">\(v[x/r]\)</span> is
the variable assignment function identical to <span class="math inline">\(v\)</span> except that it maps the variable <span class="math inline">\(x\)</span> to the real number <span class="math inline">\(r\)</span></p></li><li><p>For every formula <span class="math inline">\(\alpha\)</span>,
the f-term created by the probability operator <span class="math inline">\(prob\)</span> is interpreted as <span class="math inline">\([prob(\alpha)]^{(M,v)} = \mu(\{s \in S|(M,s,v)
\vDash \alpha \})\)</span> <strong>Example 3.1</strong></p></li></ul><p>Here are some examples showing how Lp can represent various
knowledge, not only the assertions about relations, but also assertions
about probabilities of relations.</p><ol type=1><li>“John is likely to have some type of cancer” <span class="math inline">\(prob(\exists{x}.has-cancer-type(John, x)) >
0.5\)</span></li><li>“It is more likely that John has lung cancer than any other type of
cancer” <span class="math display">\[
\begin{align*}& \forall{x}.cancer-type(x) \land x \neq lung
\rightarrow \\& \quad prob(has-cancer-type(John, lung)) >
prob(has-cancer-type(John, x))\end{align*}
\]</span></li><li>“It is more than twice as likely as that John has skin cancer than
lung cancer” <span class="math inline">\(prob(has-cancer-type(John,
skin)) > 2 * prob(has-cancer-type(John, lung))\)</span></li><li>“The probability that John has cancer lies in the interval 0.6 to
0.95” <span class="math inline">\(prob(\exists{x}.has-cancer-type(John,
x)) \in [0.6, 0.95]\)</span> <strong>Proof system</strong></li></ol><p>A proof system is used to determine whether a formula is true or
false. It should contain a set of axioms and a set of inference rules.
Below are the axioms and rules of Lp. Note that the axioms are divided
into 3 groups: one for ordinary first-order logic, one for real numbers,
and one for probability.</p><p><em>First-order Axioms</em></p><p><span class="math display">\[
\begin{align}
\alpha \rightarrow \beta \rightarrow\alpha \\
(\alpha \rightarrow \beta \rightarrow \delta) \rightarrow (\alpha
\rightarrow \beta) \rightarrow \alpha \rightarrow \delta \\
(\neg\alpha \rightarrow \beta) \rightarrow (\neg\alpha \rightarrow
\neg\beta) \rightarrow \alpha \\
\forall{x}.(\alpha \rightarrow \beta) \rightarrow \forall{x}.\alpha
\rightarrow \forall{x}.\beta \\
\forall{x}.\alpha \rightarrow \alpha(x/t) \\
t = t \\t_1 = t_{n+1} \rightarrow \dots \rightarrow t_n = t_{2n}
\rightarrow ft_1...t_n = ft_{n+1}...t_{2n} \\
t_1 = t_{n+1} \rightarrow \dots \rightarrow t_n = t_{2n} \rightarrow
Pt_1...t_n = Pt_{n+1}...t_{2n}\end{align}
\]</span></p><p><em>Field Axioms</em></p><p><span class="math display">\[
\begin{align*}
x+(y+z) = (x+y)+z \\
x+0 = x \\
x+(-1 * x) = 0 \\
x+y=y+x \\
x*(y*z) = (x*y)*z \\
x*1=x \\
x \neq 0 \rightarrow \exists{y}.(y*x=1)\\x*y=y*x \\
x*(y+z) = x*y+x*z \\
\neg (1=0)\\
\neg (x&lt;x)\\
x&lt;y \rightarrow (y&lt;z \rightarrow x&lt;z) \\
x&lt;y \lor x = y \lor y &lt; z\\x&lt;y \rightarrow x+z &lt; y+z\\
0 &lt; x \rightarrow (0&lt;y \rightarrow 0&lt;x*y)\\
\end{align*}
\]</span></p><p><em>Probability Axioms</em></p><p><span class="math display">\[
\begin{align*}prob(\alpha) \ge 0 \\
prob(\alpha) + prob(\neg\alpha) = 1 \\
prob(\alpha \land \beta) + prob(\alpha \land \neg\beta) = prob(\alpha)
\\
\alpha \rightarrow prob(\alpha) = 1\\
\forall{x}.prob(\alpha) = 1 \rightarrow prob(\forall{x}.\alpha) =
1\end{align*}
\]</span></p><p><em>Rules of Inference</em></p><p><span class="math display">\[
\begin{align*}\{\alpha, \alpha \rightarrow \beta\} \vdash \beta \\
\alpha \vdash \forall{x}.\alpha \\
\alpha = \beta \vdash prob(\alpha) = prob(\beta)\end{align*}
\]</span></p><p>The presented proof system is sound but not complete, meaning that
every proven formula is valid, but not all valid formulas can be proved
by this system. In fact, no complete proof theory exists for Lp.</p></div><div class="row middle-xs"><div class=col-xs-12></div></div><div class=row><div class=col-xs-12><a rel=license href=http://creativecommons.org/licenses/by-nc-nd/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://upload.wikimedia.org/wikipedia/commons/7/73/Cc_by-nc-nd_icon.svg></a></div></div><div style=height:50px></div><div class=site-footer></div></div></div></article><script></script></body></html>